import feedparser
import ssl
import urllib.parse
import sys
import os

# è§£å†³ SSL é—®é¢˜
if hasattr(ssl, '_create_unverified_context'):
    ssl._create_default_https_context = ssl._create_unverified_context

def search_google_news(keyword):
    """ä¸»åŠ¨å» Google News æœç´¢è¿‡å» 24 å°æ—¶çš„å¤´æ¡"""
    print(f"ğŸ•µï¸â€â™‚ï¸ [çŒäºº] æ­£åœ¨å…¨ç½‘æœç´¢: {keyword}...")
    try:
        encoded_query = urllib.parse.quote(f"{keyword} when:1d")
        rss_url = f"https://news.google.com/rss/search?q={encoded_query}&hl=en-US&gl=US&ceid=US:en"
        
        feed = feedparser.parse(rss_url)
        items = []
        seen_titles = set()
        
        for entry in feed.entries[:8]: 
            title = entry.title
            if title in seen_titles: continue
            seen_titles.add(title)
            if len(title) < 10: continue
            
            items.append({
                "source": "GoogleNews",
                "query": keyword,
                "title": title,
                "content": entry.get('summary', title),
                "link": entry.link,
                "timestamp": entry.published
            })
        return items
    except Exception as e:
        print(f"âŒ æœç´¢ {keyword} å¤±è´¥: {e}")
        return []

def get_data():
    all_items = []
    # === å®šä¹‰ä½ çš„ç‹©çŒç›®æ ‡ ===
    targets = [
        "latest AI model release",   # æŠ“ GPT-5, Gemini 3
        "new AI coding agent",       # æŠ“ Devin, Cursor ç±»
        "text to video AI tool",     # æŠ“ Sora 2, Kling ç±»
        "AI tutorial guide how-to",  # æŠ“æ•™ç¨‹
        "Andrej Karpathy",           # æŠ“å¤§ä½¬åŠ¨æ€
    ]
    
    for t in targets:
        items = search_google_news(t)
        all_items.extend(items)
        
    print(f"âœ… [çŒäºº] å…±æ•è· {len(all_items)} æ¡å®æ—¶æƒ…æŠ¥")
    return all_items
